{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34bbf40-57c3-4514-bba1-2eabd638d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import common GIS tools\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio.features\n",
    "import rioxarray as rio\n",
    "import xrspatial.multispectral as ms\n",
    "\n",
    "\n",
    "# Import Planetary Computer tools\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "import odc\n",
    "\n",
    "pc.settings.set_subscription_key('4346afa0eb8c4743b96d940704fda7d1')\n",
    "from odc.stac import stac_load\n",
    "#from odc.algo import to_rgba\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f7109d-a78d-4aaa-a1f6-d3ef48ec1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Crop_Location_Data_20221201.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7091a254-3f36-4e34-b38f-7a26a731eadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=pc.sign_inplace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e402547-1897-49c0-8293-305e66ef56c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentinel2_data(latlong, time_slice):\n",
    "\n",
    "    box_size_deg = 0.10 # Surrounding box in degrees\n",
    "    latlong=latlong.replace('(','').replace(')','').replace(' ','').split(',')\n",
    "    \n",
    "    latlong[0] , latlong[1] = float(latlong[0]), float(latlong[1])\n",
    "    min_lon = latlong[1]-box_size_deg/2\n",
    "    min_lat = latlong[0]-box_size_deg/2\n",
    "    max_lon = latlong[1]+box_size_deg/2\n",
    "    max_lat = latlong[0]+box_size_deg/2\n",
    "    bounds = (min_lon, min_lat, max_lon, max_lat)\n",
    "    \n",
    "\n",
    "    searchh = catalog.search(collections=[\"sentinel-2-l2a\"], bbox=bounds, datetime=time_slice)\n",
    "    items = list(searchh.get_all_items())\n",
    "    \n",
    "    # Define the pixel resolution for the final product\n",
    "    # Define the scale according to our selected crs, so we will use degrees\n",
    "    res = 20  # meters per pixel \n",
    "    scale = res / 111320.0 # degrees per pixel for CRS:4326\n",
    "    \n",
    "    xx = stac_load(items, bands=[\"red\", \"green\", \"blue\", \"nir\", \"SCL\"], crs=\"EPSG:4326\", resolution=scale, chunks={\"x\": 2048, \"y\": 2048}, dtype=\"uint16\", patch_url=pc.sign, bbox=bounds )\n",
    "\n",
    "    return xx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "345403c4-4816-4550-8d47-1794992966a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentinel1_data(latlong,time_slice,assets):\n",
    "    '''\n",
    "    Returns VV and VH values for a given latitude and longitude \n",
    "    Attributes:\n",
    "    latlong - A tuple with 2 elements - latitude and longitude\n",
    "    time_slice - Timeframe for which the VV and VH values have to be extracted\n",
    "    assets - A list of bands to be extracted\n",
    "    '''\n",
    "\n",
    "    box_size_deg = 0.0004 # Surrounding box in degrees\n",
    "    latlong=latlong.replace('(','').replace(')','').replace(' ','').split(',')\n",
    "    \n",
    "    latlong[0] , latlong[1] = float(latlong[0]), float(latlong[1])\n",
    "    min_lon = latlong[1]-box_size_deg/2\n",
    "    min_lat = latlong[0]-box_size_deg/2\n",
    "    max_lon = latlong[1]+box_size_deg/2\n",
    "    max_lat = latlong[0]+box_size_deg/2\n",
    "    bounds = (min_lon, min_lat, max_lon, max_lat)\n",
    "\n",
    "    search = catalog.search(collections=[\"sentinel-1-rtc\"], bbox=bounds, datetime=time_slice)\n",
    "    items = list(search.get_all_items())\n",
    "    res = 10  # meters per pixel \n",
    "    scale = res / 111320.0 # degrees per pixel for crs=4326\n",
    "\n",
    "    data = stac_load(items,bands=[\"vv\", \"vh\"], patch_url=pc.sign, bbox=bounds, crs=\"EPSG:4326\", resolution=scale,chunks={\"x\": 2048, \"y\": 2048})\n",
    "    mean = data.mean(dim=['latitude','longitude']).compute()\n",
    "\n",
    "    return mean.vh.var().to_numpy(),mean.vv.var().to_numpy()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af7c925-e73a-44f8-97a6-9c6c3efcd8d6",
   "metadata": {},
   "source": [
    "for i in range(len(items)):\n",
    "        data = stac_load([items[i]],bands=[\"vv\", \"vh\"], patch_url=pc.sign, bbox=bounds, crs=\"EPSG:4326\", resolution=scale,chunks={\"x\": 2048, \"y\": 2048}).isel(time = 0)\n",
    "        vh.append(data[\"vh\"].astype(\"float\").values.tolist()[0][0])\n",
    "        vv.append(data[\"vv\"].astype(\"float\").values.tolist()[0][0])\n",
    "    vh = sum(vh)/len(vh)\n",
    "    vv = sum(vv)/len(vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f3e482-a51e-48fc-99e3-6b6360f83738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud_filtering(data):\n",
    "    # Create a mask for no data, saturated data, clouds, cloud shadows, and water\n",
    "    cloud_mask = \\\n",
    "        (data.SCL != 0) & \\\n",
    "        (data.SCL != 1) & \\\n",
    "        (data.SCL != 3) & \\\n",
    "        (data.SCL != 6) & \\\n",
    "        (data.SCL != 8) & \\\n",
    "        (data.SCL != 9) & \\\n",
    "        (data.SCL != 10)\n",
    "    # Apply cloud mask ... NO Clouds, NO Cloud Shadows and NO Water pixels\n",
    "    # All masked pixels are converted to \"No Data\" and stored as 16-bit integers\n",
    "    cleaned_data = data.where(cloud_mask).astype(\"uint16\")\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6627f0e0-75bb-4321-b57c-2122d6355819",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = \"2021-11-01/2022-05-01\"\n",
    "assests = ['vh','vv']\n",
    "vh_vv = []\n",
    "coords = '(10.322364360592521, 105.27843410554115)'\n",
    "\n",
    "p = get_sentinel1_data(coords, time_slice, assests)\n",
    "vh_vv.append( [float(p[0]), float(p[1]) ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f47cf9-221c-4ada-8f6f-57a0beff2122",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m Y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass of Land\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude and Longitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(X, Y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,stratify\u001b[38;5;241m=\u001b[39mY,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "Y = data[\"Class of Land\"]\n",
    "X = data['Latitude and Longitude']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1,stratify=Y,random_state=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d89426-8269-4ad5-8913-fa45b920e9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 1/600 [00:21<3:30:09, 21.05s/it]"
     ]
    }
   ],
   "source": [
    "time_slice = \"2021-11-01/2022-05-01\"\n",
    "assests = ['vh','vv']\n",
    "vh_vv = []\n",
    "for coords in tqdm(data['Latitude and Longitude']):\n",
    "    p = get_sentinel1_data(coords, time_slice, assests)\n",
    "    vh_vv.append( [float(p[0]), float(p[1]) ] )\n",
    "vh_vv_data = pd.DataFrame(vh_vv, columns = ['vh','vv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ce114-e80e-4a2e-bee8-52f083af1e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vh_vv_data\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9786dac1-d37f-462b-92a3-8c77eed138c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = \"2021-11-01/2022-05-01\"\n",
    "variance = []\n",
    "for coords in tqdm(data['Latitude and Longitude']):\n",
    "    mean_clean = cloud_filtering(get_sentinel2_data(coords, time_slice)).mean(dim=['longitude','latitude'])\n",
    "    ndvi_mean_clean = (mean_clean.nir-mean_clean.red)/(mean_clean.nir+mean_clean.red)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
